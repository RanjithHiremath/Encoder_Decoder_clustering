{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a76d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "import random\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances\n",
    "from validclust import dunn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908e4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_array):\n",
    "    # converting colored images to gray scale\n",
    "    gray = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
    "    # Reshaping array to a single row with 1024 columns\n",
    "    gray_reshaped = gray.reshape(1, 1024)\n",
    "    # Scaling the features to values between zero and 1\n",
    "    scaled = gray_reshaped / (255)\n",
    "    return gray_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f2b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(inp_point, cluster_centroids):\n",
    "    # calculating euclidean distance between the data point and cluster centroid.\n",
    "    distances = [np.linalg.norm(inp_point - ctr) for ctr in cluster_centroids]\n",
    "\n",
    "    cluster_no = distances.index(min(distances))\n",
    "\n",
    "    return cluster_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0b603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recentre_centroids(cluster, data):\n",
    "    # Taking the cluster number and data points as input\n",
    "    # grouping together the data points with same cluster number\n",
    "    unique_clusters = list(set(cluster))\n",
    "    clustered_data_dict = {}\n",
    "    # for all the unique clusters getting the data points belonging to that clusters\n",
    "    for unq_num in unique_clusters: \n",
    "        same_cluster = []\n",
    "        for num, point in zip(cluster, data):\n",
    "            if unq_num == num:\n",
    "                same_cluster.append(point)\n",
    "        clustered_data_dict[unq_num] = np.array(same_cluster)\n",
    "    # updating centroids as mean values of data points present in that cluster\n",
    "    new_centroids = [ np.mean(value, axis = 0) for key, value in clustered_data_dict.items() ]\n",
    "    return new_centroids, clustered_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c200ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(data, k, patience):\n",
    "    # chossing k number of centroids randomly.\n",
    "    cluster_centroids = []\n",
    "    terminate = False\n",
    "    patience_count = 0\n",
    "    cluster_old = []\n",
    "    random.seed(99)\n",
    "    for i in range(k):\n",
    "        cluster_centroids.append(random.choice(data))\n",
    "    # calculating distances and assigning clusters\n",
    "    iter_no = 1\n",
    "    # The stop condition is if the cluster formed are same \n",
    "    # for patience number of times\n",
    "    while terminate == False and patience_count < patience:\n",
    "        if iter_no != 1:\n",
    "            cluster_centroids, clustered_data_dict = recentre_centroids(cluster, data)\n",
    "        cluster = [ calculate_distance(point, cluster_centroids) for point in data ]\n",
    "        if cluster == cluster_old:\n",
    "            patience_count += 1\n",
    "#             print(\"patience reached\", patience_count)\n",
    "            if patience_count >= patience:\n",
    "                terminate = True\n",
    "        else:\n",
    "            patience_count = 0\n",
    "            terminate = False\n",
    "        cluster_old = cluster\n",
    "        iter_no += 1\n",
    "#         print(\" no of iterations : \", iter_no)\n",
    "    return cluster, iter_no, clustered_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9f5ad",
   "metadata": {},
   "source": [
    "###  loading cifar10 data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d302575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1ca9bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train  (50000, 32, 32, 3)\n",
      "shape of test (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of train \", X_train.shape)\n",
    "print(\"shape of test\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3058db",
   "metadata": {},
   "source": [
    "### Using only test data for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd236a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape of processed data :  (10000, 1024)\n"
     ]
    }
   ],
   "source": [
    "processed_X_test = np.array([ preprocess(img_array) for img_array in X_test ])\n",
    "processed_X_test = processed_X_test.reshape(10000, 1024)\n",
    "print(\" shape of processed data : \", processed_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4ec4d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 1/10 [00:04<00:41,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.17953866855626427\n",
      "dunns index is  0.0919845985373622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 2/10 [00:08<00:33,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 3 The average silhouette_score is : 0.11590471626887923\n",
      "dunns index is  0.09005725342476706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████▏                              | 3/10 [00:14<00:35,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 4 The average silhouette_score is : 0.10320309347694681\n",
      "dunns index is  0.08368556326723489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 4/10 [00:23<00:38,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 5 The average silhouette_score is : 0.08747868928225702\n",
      "dunns index is  0.08249664087520184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████                      | 5/10 [00:37<00:46,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 6 The average silhouette_score is : 0.07902653793812217\n",
      "dunns index is  0.09142460937653932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████▍                 | 6/10 [00:48<00:38,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 7 The average silhouette_score is : 0.07561892205073495\n",
      "dunns index is  0.08310120111043925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████▊             | 7/10 [01:05<00:36, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 8 The average silhouette_score is : 0.06647005100891981\n",
      "dunns index is  0.09773129466140822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████▏        | 8/10 [01:39<00:38, 19.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 9 The average silhouette_score is : 0.06468473843763464\n",
      "dunns index is  0.08665430985693591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████▌    | 9/10 [02:18<00:25, 25.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 10 The average silhouette_score is : 0.05402163199264537\n",
      "dunns index is  0.08993630211024856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [02:52<00:00, 17.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 11 The average silhouette_score is : 0.054782964733661274\n",
      "dunns index is  0.09143259681851422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "dist = pairwise_distances(processed_X_test)\n",
    "res = []\n",
    "for n_clust in tqdm.tqdm(range(2, 12)):\n",
    "    k = n_clust\n",
    "    clusters_nos, iter_no, clustered_data_dict = clustering(processed_X_test, k, patience = 5)\n",
    "    silhouette_avg = silhouette_score(processed_X_test, clusters_nos)\n",
    "    dunn_index = dunn(dist, np.array(clusters_nos))\n",
    "    print(\"For n_clusters =\", k,\"The average silhouette_score is :\", silhouette_avg)\n",
    "    print(\"dunns index is \", dunn_index)\n",
    "    res.append([k, silhouette_avg, dunn_index] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd0f27",
   "metadata": {},
   "source": [
    "### For 10 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0211fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 10 The average silhouette_score is : 0.05402163199264537\n",
      "dunns index is  0.08993630211024856\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "clusters_nos, iter_no, clustered_data_dict = clustering(processed_X_test, k, patience = 5)\n",
    "silhouette_avg = silhouette_score(processed_X_test, clusters_nos)\n",
    "dunn_index = dunn(dist, np.array(clusters_nos))\n",
    "print(\"For n_clusters =\", k,\"The average silhouette_score is :\", silhouette_avg)\n",
    "print(\"dunns index is \", dunn_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tf_base': conda)",
   "language": "python",
   "name": "python3812jvsc74a57bd03b07a3793a716328c1635aea92b408540c9d156e3b214f530ac18c4551fe1c64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
